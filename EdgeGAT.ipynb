{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "-R9lM1_rVS2j",
        "outputId": "2f1d24e3-9e7b-4cc9-8eab-4fa39271c61b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7d93c9919f55>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDGLDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.data import DGLDataset\n",
        "from torch.optim import Adam\n",
        "import tqdm as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, f1_score, recall_score, roc_auc_score\n",
        "import optuna\n",
        "from optuna import trial\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(12)\n",
        "torch.manual_seed(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Setting"
      ],
      "metadata": {
        "id": "TR9nRhE8Vo2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dgl.__version__)"
      ],
      "metadata": {
        "id": "AVDRJUqFVlqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLlbWBIzVnqD",
        "outputId": "3b897e61-25f3-4cd7-f575-2e774440f847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 30 08:08:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_availabe() else 'cpu')"
      ],
      "metadata": {
        "id": "G8zujTKwVnsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "SzD_VR4WWVCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CSVDataset('your_folder_route')\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "ewG4I2T_Vnu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph0, data0 = dataset[0]\n",
        "print(graph0)"
      ],
      "metadata": {
        "id": "K9pi_5DIVnxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data0)"
      ],
      "metadata": {
        "id": "tuA_hqkuVnzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make self loop\n",
        "self_dataset = []\n",
        "for graph, data in dataset:\n",
        "  graph = dgl.add_self_loop(graph)\n",
        "  self_dataset.append((graph, data))\n",
        "print(len(self_dataset))"
      ],
      "metadata": {
        "id": "J0sldjRbVn2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph0, data0 = self_dataset[0]\n",
        "print(graph0)"
      ],
      "metadata": {
        "id": "tKfna4_-Vn4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data0)"
      ],
      "metadata": {
        "id": "qnjmJUjJVn7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_fetas = graph0.ndata['feat'].shape[1]\n",
        "edge_fetas = graph0.edata['feat'].shape[1]"
      ],
      "metadata": {
        "id": "bhC-ls-qi3Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train / Test Split, Batch"
      ],
      "metadata": {
        "id": "UlVNMzodW6a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array([self_dataset[i][1] for i in range(len(self_dataset))])\n",
        "\n",
        "neg_indices = np.where(labels == 0)[0]\n",
        "pos_indices = np.where(labels == 1)[0]\n",
        "\n",
        "train_ratio ,val_ratio, test_ratio = 0.6, 0.2, 0.2\n",
        "\n",
        "train_neg, val_test_neg = train_test_split(neg_indices, train_size = train_ratio, random_state = 12)\n",
        "val_neg, test_neg = train_test_split(val_test_neg, train_size = 0.5, random_state = 12)\n",
        "\n",
        "train_pos, val_test_pos = train_test_split(pos_indices, train_size = train_ratio, random_state = 12)\n",
        "val_pos, test_pos = train_test_split(val_test_pos, train_size = 0.5, random_state = 12)\n",
        "\n",
        "train_indices = np.concatenate([train_neg, train_pos])\n",
        "val_indices = np.concatenate([val_neg, val_pos])\n",
        "test_indices = np.concatenate([test_neg, test_pos])"
      ],
      "metadata": {
        "id": "bHnyLf3Y23T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = [], [], []\n",
        "\n",
        "for index in train_indices:\n",
        "  train_dataset.append(self_dataset[index])\n",
        "np.random.shuffle(train_dataset)\n",
        "\n",
        "for index in val_indices:\n",
        "  val_dataset.append(self_dataset[index])\n",
        "np.random.shuffle(val_dataset)\n",
        "\n",
        "for index in test_indices:\n",
        "  test_dataset.append(self_dataset[index])\n",
        "np.random.shuffle(test_dataset)\n"
      ],
      "metadata": {
        "id": "cqqUYuqQ33RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling"
      ],
      "metadata": {
        "id": "l7y7T2mCYU-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import EdgeGATConv, AvgPooling\n",
        "\n",
        "class EdgeGATModel(nn.Moudle):\n",
        "  def __init__(self, in_feats, edge_feats, hidden_feats, out_feats, num_heads):\n",
        "    super(EdgeGATModel, self).__init__()\n",
        "    self.edge_gat1 = EdgeGATConv(in_feats = in_feats,\n",
        "                                 edge_feats = edge_feats,\n",
        "                                 out_feats = hidden_feats,\n",
        "                                 num_heads = num_heads)\n",
        "    self.edge_gat2 = EdgeGATConv(in_feats = hidden_feats,\n",
        "                                 edge_feats = edge_feats,\n",
        "                                 out_feats = hidden_feats,\n",
        "                                 num_heads = num_heads)\n",
        "    self.Linear = nn.Linear(hidden_feats, 1)\n",
        "\n",
        "  def forward(self, graph, node_feats, edge_feats, num_heads):\n",
        "    hidden1 = self.edge_gat1(graph, node_feats, edge_feats)\n",
        "    hidden1 = torch.mean(hidden1, dim = 1, keepdim = True)\n",
        "    hidden1 = hidden1.view(hidden1.shape[0], -1)\n",
        "    hidden1 = F.leaky_relu(hidden1)\n",
        "\n",
        "    hidden2 = self.edge_gat2(graph, hidden1, edge_feats)\n",
        "    hidden2 = torch.mean(hidden2, dim = 1, keepdim = True)\n",
        "    hidden2 = hidden2.view(hidden2.shape[0], -1)\n",
        "    hidden2 = F.leaky_relu(hidden2)\n",
        "    graph.ndata['h'] = hidden2\n",
        "\n",
        "    hg = dgl.mean_nodes(graph, 'h')\n",
        "    hg = self.Linear(hg)\n",
        "    return hg"
      ],
      "metadata": {
        "id": "h_c-u_VAVoFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Params (Optuna)"
      ],
      "metadata": {
        "id": "GFHMiJBtjGmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  hidden_feats = 2 ** trail.suggest_int('hidden_feats', 3, 5)\n",
        "  num_heads = trial.suggest_int('num_heads', 2, 5)\n",
        "  learning_rate = 10 ** trial.suggest_int('learning_rate', -5, -2)\n",
        "  num_epochs = trial.suggest_int('num_epochs', 10, 100, 10)\n",
        "  batch_size = 2 ** trial.suggest_int('batch_size', 5, 8)\n",
        "\n",
        "  train_dataloader = GraphDataLoader(\n",
        "      train_dataset,\n",
        "      batch_size = batch_size,\n",
        "      drop_last = False)\n",
        "\n",
        "  val_dataloader = GraphDataLoader(\n",
        "      val_dataset,\n",
        "      batch_size = batch_size,\n",
        "      drop_last = False)\n",
        "\n",
        "  model = EdgeGATModel(in_feats = in_feats,\n",
        "                     edge_feats = edge_feats,\n",
        "                     hidden_feats = hidden_feats,\n",
        "                     num_heads = num_heads)\n",
        "\n",
        "  optimizer = Adam(model.parameters(), lr = learning_Rate)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  model.train()\n",
        "  for batched_graph, labels in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(batched_graph, batched_graph.ndata['feat'], batched_graph.edata['feat'], num_heads)\n",
        "    loss= criterion(pred, labels.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  val_loss = 0\n",
        "  step = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batched_graph, labels in val_dataloader:\n",
        "      step += 1\n",
        "      pred = model(batched_graph, batched_graph.ndata['feat'], batched_graph.edata['feat'], num_heads)\n",
        "      loss= criterion(pred, labels.float())\n",
        "      val_loss += loss.item()\n",
        "      average_val_loss = val_loss / step\n",
        "      trial.report(average_val_loss, step)\n",
        "      if trial.should_prune():\n",
        "        raise optuna.TrialPruned()\n",
        "\n",
        "  return average_val_loss"
      ],
      "metadata": {
        "id": "DJJFdlmhj4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = TPESampler(seed = 12)\n",
        "study = optuna.create_study(\n",
        "    study_name = 'EdgeGAT_OPT',\n",
        "    direction = 'minimize',\n",
        "    sampler = sampler)\n",
        "study.optimize(objective, n_trials = 100)\n",
        "print('Best Score : ', study.best_value)\n",
        "print('Best Trial : ', study.best_trial.params)"
      ],
      "metadata": {
        "id": "lGMWTlV9lw_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "Rd4qB_aVZgiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = GraphDataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 2 ** study.best_trial.params['batch_size'],\n",
        "    drop_last = False\n",
        ")\n",
        "\n",
        "val_dataloader = GraphDataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = 2 ** study.best_trial.params['batch_size'],\n",
        "    drop_last = False\n",
        ")\n",
        "\n",
        "test_dataloader = GraphDataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 2 ** study.best_trial.params['batch_size'],\n",
        "    drop_last = False\n",
        ")"
      ],
      "metadata": {
        "id": "NWTFnWR2Vn99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_feats = 2 ** study.best_trial.params['hidden_feats']\n",
        "learning_rate = 10 ** study.best_trial.params['learning_rate']\n",
        "\n",
        "num_heads = study.best_trial.params['num_heads']\n",
        "num_epochs = study.best_trial.params['num_epochs']"
      ],
      "metadata": {
        "id": "qy3UqyMaVoK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EdgeGATModel(in_feats = in_feats,\n",
        "                     edge_feats = edge_feats,\n",
        "                     hidden_feats = hidden_feats,\n",
        "                     num_heads = num_heads)\n",
        "optimizer = Adam(model.parameters(), lr = learning_Rate)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "dwDiM-Z5VoNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_epochs),desc = 'Model Training')\n",
        "\n",
        "model.train()\n",
        "for epoch in progress_bar:\n",
        "  for batched_graph, labels in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(batched_graph, batched_graph.ndata['feat'], batched_graph.edata['feat'], num_heads)\n",
        "    loss = criterion(pred, labels.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    progress_bar.set_description(f'Epoch - {epoch + 1}')"
      ],
      "metadata": {
        "id": "y_CyXdXKVoSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation (Find Optimal Threshold)"
      ],
      "metadata": {
        "id": "DgZ9ae4q44XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "GtL_TI8a4-RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_threshold(model, dataloader):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    all_pred = []\n",
        "    all_labels = []\n",
        "    for batched_graph, labels in dataloader:\n",
        "      pred = model(batched_graph, batched_graph.ndata['feat'], batched_graph.edata['feat'], num_heads)\n",
        "      all_pred.append(pred)\n",
        "      all_labels.append(labels.float())\n",
        "\n",
        "    all_pred = torch.sigmoid(torch.cat(all_pred))\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    precision, recall, threshold = precision_recall_curve(all_labels, all_pred)\n",
        "    f1 = precision * recall * 2 / (precision + recall)\n",
        "    ix = np.argmax(f1)\n",
        "    opt_thr = threshold[ix]\n",
        "    print(f'Optimal Threshold : {opt_thr:.2f}, F1 Score : {f1[ix]:.2f}')\n",
        "\n",
        "    plt.plot(recall, precision, marker = ',', label = 'EdgeGAT')\n",
        "    plt.scatter(recall[ix], precision[ix], marker = 'o', color = 'black', label = 'Optimal')\n",
        "    plt.title('Precision - Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return opt_thr"
      ],
      "metadata": {
        "id": "RsSjNaJi5E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_threshold = find_optimal_threshold(model, val_dataloader)"
      ],
      "metadata": {
        "id": "OWIdpLJi6P8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test (Result)"
      ],
      "metadata": {
        "id": "qOkPRqFS6Uwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, threshold):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    all_pred = []\n",
        "    all_labels = []\n",
        "    for batched_graph, labels in dataloader:\n",
        "      pred = model(batched_graph, batched_graph.ndata['feat'], batched_graph.edata['feat'], num_heads)\n",
        "      all_pred.append(pred)\n",
        "      all_labels.append(labels.float())\n",
        "\n",
        "    all_pred = torch.sigmoid(torch.cat(all_pred))\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    pred_labels = (all_pred >= threshold).long()\n",
        "    f1 = f1_score(all_labels, pred_labels)\n",
        "    recall = recall_score(all_labels, pred_labels)\n",
        "    accuracy = (pred_labels == all_labels).float().mean().item()\n",
        "\n",
        "    return f1, recall, accuracy"
      ],
      "metadata": {
        "id": "107ZjOLXVoUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1, recall, accuracy = evaluate(model, test_dataloader, best_threshold)\n",
        "print(f\"Accuracy : {accuracy:.2f}, Recall : {recall:.2f}, F1 : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "Y8PgR5F3VoXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SVMqtljVoaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuuO8lT6VocR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xo6_C17TVoe5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}